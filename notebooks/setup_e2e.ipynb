{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ae5daf-655f-457c-98ba-e7aea50a928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "\n",
    "from attn_sae import *\n",
    "from sae_training.sae_group import SAEGroup\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "from e2e_sae import SAETransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e717c-70c9-43c0-aac1-8c744e6bcb8c",
   "metadata": {},
   "source": [
    "# First Let's See What I have to load for error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d53c75-6cf5-49c0-9538-7c03a1e04032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import error_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a7bb81-ab1e-422d-b5b3-79e6ad9f9ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageModelSAERunnerConfig(model_name='gpt2-small', hook_point='blocks.0.hook_resid_pre', hook_point_layer=0, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/gpt2-small/blocks.0.hook_resid_pre', d_in=768, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device='mps', seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=32, from_pretrained_path=None, d_sae=24576, l1_coefficient=8e-05, lp_norm=1, lr=0.0004, lr_scheduler_name=None, lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=True, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-08, log_to_wandb=True, wandb_project='mats_sae_training_gpt2_small_resid_pre_5', run_name='24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=10, checkpoint_path='checkpoints/y1t51byy')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellee/Library/Caches/pypoetry/virtualenvs/sae-pathology-s4la4Q7B-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is not tokenized! Updating config.\n",
      "Run name: 24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    }
   ],
   "source": [
    "sae_wes, model_wes = error_eval.load_sae(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc317df0-a4c3-4112-b317-29af7c1d1513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sae_training.sparse_autoencoder.SparseAutoencoder"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41dca05-ba17-478e-841c-3f2338a3d9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.HookedTransformer.HookedTransformer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074f5db-b6e8-4aba-a6cb-98f42d50d7d7",
   "metadata": {},
   "source": [
    "# Let's try to load the e2e_sae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d639090-d530-4096-9507-3ebbc4f03ccd",
   "metadata": {},
   "source": [
    "7nkdr21r: e2e_ds, L0 of 131, CE of 0.037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b60d0ee-2e50-460f-a527-6696c5d9d4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellee/Library/Caches/pypoetry/virtualenvs/sae-pathology-s4la4Q7B-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_id = \"7nkdr21r\"\n",
    "text = \"sparsify/gpt2/\" + model_id\n",
    "sae_transformer_model = SAETransformer.from_wandb(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877492a7-0150-4333-8f45-869155a68ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sae_transformer_model.tlens_model\n",
    "sae = sae_transformer_model.saes[\"blocks-6-hook_resid_pre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa8fc5fc-6236-4214-85a7-7d973e83121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.ModuleDict"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51bbb8fe-df9f-4d88-bf7c-bfb5d6c13a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e2e_sae.models.sparsifiers.SAE"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde91b60-171b-4f05-b909-0dfc54ae6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6061fb96-cde5-4604-96d4-77f76bd52f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n"
     ]
    }
   ],
   "source": [
    "sae = sae.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9059bd-6e15-4ea9-bf20-ceff7a055a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensor = torch.load(\"../token_tensor.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540907ab-f2ca-4759-9a16-813faf7f8303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                                                   | 4/250 [09:35<13:29:49, 197.52s/it]"
     ]
    }
   ],
   "source": [
    "layer = str(6)\n",
    "hook_loc = \"resid_pre\"\n",
    "pos = None\n",
    "batch_size = 64\n",
    "\n",
    "result_df = error_eval.run_error_eval_experiment(\n",
    "    sae, \n",
    "    model, \n",
    "    token_tensor, \n",
    "    layer, \n",
    "    batch_size, \n",
    "    pos, \n",
    "    hook_loc,\n",
    "    e2e = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c073f-5042-4054-a2e3-b871da8c63db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
